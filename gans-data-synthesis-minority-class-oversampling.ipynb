{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport torch\n\ntorch.cuda.is_available()","execution_count":55,"outputs":[{"output_type":"execute_result","execution_count":55,"data":{"text/plain":"True"},"metadata":{}}]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"DATA_PATH = \"../input/creditcardfraud/creditcard.csv\"\nBATCH_SIZE = 64\nNOISE_DIM = 32\nFEATURES_DIM = 28\nGENERATOR_LEARNING_RATE = 0.0002\nDISCRIMINATOR_LEARNING_RATE = 0.0003\nTRAIN_EPOCHS = 16\nTRAIN_STEPS = 64\nK_DISCRIMINATOR_STEPS = 5","execution_count":56,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"df = pd.read_csv(DATA_PATH)\ndf.head()","execution_count":57,"outputs":[{"output_type":"execute_result","execution_count":57,"data":{"text/plain":"   Time        V1        V2        V3        V4        V5        V6        V7  \\\n0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n\n         V8        V9  ...       V21       V22       V23       V24       V25  \\\n0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n\n        V26       V27       V28  Amount  Class  \n0 -0.189115  0.133558 -0.021053  149.62      0  \n1  0.125895 -0.008983  0.014724    2.69      0  \n2 -0.139097 -0.055353 -0.059752  378.66      0  \n3 -0.221929  0.062723  0.061458  123.50      0  \n4  0.502292  0.219422  0.215153   69.99      0  \n\n[5 rows x 31 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Time</th>\n      <th>V1</th>\n      <th>V2</th>\n      <th>V3</th>\n      <th>V4</th>\n      <th>V5</th>\n      <th>V6</th>\n      <th>V7</th>\n      <th>V8</th>\n      <th>V9</th>\n      <th>...</th>\n      <th>V21</th>\n      <th>V22</th>\n      <th>V23</th>\n      <th>V24</th>\n      <th>V25</th>\n      <th>V26</th>\n      <th>V27</th>\n      <th>V28</th>\n      <th>Amount</th>\n      <th>Class</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.0</td>\n      <td>-1.359807</td>\n      <td>-0.072781</td>\n      <td>2.536347</td>\n      <td>1.378155</td>\n      <td>-0.338321</td>\n      <td>0.462388</td>\n      <td>0.239599</td>\n      <td>0.098698</td>\n      <td>0.363787</td>\n      <td>...</td>\n      <td>-0.018307</td>\n      <td>0.277838</td>\n      <td>-0.110474</td>\n      <td>0.066928</td>\n      <td>0.128539</td>\n      <td>-0.189115</td>\n      <td>0.133558</td>\n      <td>-0.021053</td>\n      <td>149.62</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.0</td>\n      <td>1.191857</td>\n      <td>0.266151</td>\n      <td>0.166480</td>\n      <td>0.448154</td>\n      <td>0.060018</td>\n      <td>-0.082361</td>\n      <td>-0.078803</td>\n      <td>0.085102</td>\n      <td>-0.255425</td>\n      <td>...</td>\n      <td>-0.225775</td>\n      <td>-0.638672</td>\n      <td>0.101288</td>\n      <td>-0.339846</td>\n      <td>0.167170</td>\n      <td>0.125895</td>\n      <td>-0.008983</td>\n      <td>0.014724</td>\n      <td>2.69</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1.0</td>\n      <td>-1.358354</td>\n      <td>-1.340163</td>\n      <td>1.773209</td>\n      <td>0.379780</td>\n      <td>-0.503198</td>\n      <td>1.800499</td>\n      <td>0.791461</td>\n      <td>0.247676</td>\n      <td>-1.514654</td>\n      <td>...</td>\n      <td>0.247998</td>\n      <td>0.771679</td>\n      <td>0.909412</td>\n      <td>-0.689281</td>\n      <td>-0.327642</td>\n      <td>-0.139097</td>\n      <td>-0.055353</td>\n      <td>-0.059752</td>\n      <td>378.66</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1.0</td>\n      <td>-0.966272</td>\n      <td>-0.185226</td>\n      <td>1.792993</td>\n      <td>-0.863291</td>\n      <td>-0.010309</td>\n      <td>1.247203</td>\n      <td>0.237609</td>\n      <td>0.377436</td>\n      <td>-1.387024</td>\n      <td>...</td>\n      <td>-0.108300</td>\n      <td>0.005274</td>\n      <td>-0.190321</td>\n      <td>-1.175575</td>\n      <td>0.647376</td>\n      <td>-0.221929</td>\n      <td>0.062723</td>\n      <td>0.061458</td>\n      <td>123.50</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2.0</td>\n      <td>-1.158233</td>\n      <td>0.877737</td>\n      <td>1.548718</td>\n      <td>0.403034</td>\n      <td>-0.407193</td>\n      <td>0.095921</td>\n      <td>0.592941</td>\n      <td>-0.270533</td>\n      <td>0.817739</td>\n      <td>...</td>\n      <td>-0.009431</td>\n      <td>0.798278</td>\n      <td>-0.137458</td>\n      <td>0.141267</td>\n      <td>-0.206010</td>\n      <td>0.502292</td>\n      <td>0.219422</td>\n      <td>0.215153</td>\n      <td>69.99</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 31 columns</p>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.describe()","execution_count":58,"outputs":[{"output_type":"execute_result","execution_count":58,"data":{"text/plain":"                Time            V1            V2            V3            V4  \\\ncount  284807.000000  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \nmean    94813.859575  3.919560e-15  5.688174e-16 -8.769071e-15  2.782312e-15   \nstd     47488.145955  1.958696e+00  1.651309e+00  1.516255e+00  1.415869e+00   \nmin         0.000000 -5.640751e+01 -7.271573e+01 -4.832559e+01 -5.683171e+00   \n25%     54201.500000 -9.203734e-01 -5.985499e-01 -8.903648e-01 -8.486401e-01   \n50%     84692.000000  1.810880e-02  6.548556e-02  1.798463e-01 -1.984653e-02   \n75%    139320.500000  1.315642e+00  8.037239e-01  1.027196e+00  7.433413e-01   \nmax    172792.000000  2.454930e+00  2.205773e+01  9.382558e+00  1.687534e+01   \n\n                 V5            V6            V7            V8            V9  \\\ncount  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \nmean  -1.552563e-15  2.010663e-15 -1.694249e-15 -1.927028e-16 -3.137024e-15   \nstd    1.380247e+00  1.332271e+00  1.237094e+00  1.194353e+00  1.098632e+00   \nmin   -1.137433e+02 -2.616051e+01 -4.355724e+01 -7.321672e+01 -1.343407e+01   \n25%   -6.915971e-01 -7.682956e-01 -5.540759e-01 -2.086297e-01 -6.430976e-01   \n50%   -5.433583e-02 -2.741871e-01  4.010308e-02  2.235804e-02 -5.142873e-02   \n75%    6.119264e-01  3.985649e-01  5.704361e-01  3.273459e-01  5.971390e-01   \nmax    3.480167e+01  7.330163e+01  1.205895e+02  2.000721e+01  1.559499e+01   \n\n       ...           V21           V22           V23           V24  \\\ncount  ...  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \nmean   ...  1.537294e-16  7.959909e-16  5.367590e-16  4.458112e-15   \nstd    ...  7.345240e-01  7.257016e-01  6.244603e-01  6.056471e-01   \nmin    ... -3.483038e+01 -1.093314e+01 -4.480774e+01 -2.836627e+00   \n25%    ... -2.283949e-01 -5.423504e-01 -1.618463e-01 -3.545861e-01   \n50%    ... -2.945017e-02  6.781943e-03 -1.119293e-02  4.097606e-02   \n75%    ...  1.863772e-01  5.285536e-01  1.476421e-01  4.395266e-01   \nmax    ...  2.720284e+01  1.050309e+01  2.252841e+01  4.584549e+00   \n\n                V25           V26           V27           V28         Amount  \\\ncount  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05  284807.000000   \nmean   1.453003e-15  1.699104e-15 -3.660161e-16 -1.206049e-16      88.349619   \nstd    5.212781e-01  4.822270e-01  4.036325e-01  3.300833e-01     250.120109   \nmin   -1.029540e+01 -2.604551e+00 -2.256568e+01 -1.543008e+01       0.000000   \n25%   -3.171451e-01 -3.269839e-01 -7.083953e-02 -5.295979e-02       5.600000   \n50%    1.659350e-02 -5.213911e-02  1.342146e-03  1.124383e-02      22.000000   \n75%    3.507156e-01  2.409522e-01  9.104512e-02  7.827995e-02      77.165000   \nmax    7.519589e+00  3.517346e+00  3.161220e+01  3.384781e+01   25691.160000   \n\n               Class  \ncount  284807.000000  \nmean        0.001727  \nstd         0.041527  \nmin         0.000000  \n25%         0.000000  \n50%         0.000000  \n75%         0.000000  \nmax         1.000000  \n\n[8 rows x 31 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Time</th>\n      <th>V1</th>\n      <th>V2</th>\n      <th>V3</th>\n      <th>V4</th>\n      <th>V5</th>\n      <th>V6</th>\n      <th>V7</th>\n      <th>V8</th>\n      <th>V9</th>\n      <th>...</th>\n      <th>V21</th>\n      <th>V22</th>\n      <th>V23</th>\n      <th>V24</th>\n      <th>V25</th>\n      <th>V26</th>\n      <th>V27</th>\n      <th>V28</th>\n      <th>Amount</th>\n      <th>Class</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>284807.000000</td>\n      <td>2.848070e+05</td>\n      <td>2.848070e+05</td>\n      <td>2.848070e+05</td>\n      <td>2.848070e+05</td>\n      <td>2.848070e+05</td>\n      <td>2.848070e+05</td>\n      <td>2.848070e+05</td>\n      <td>2.848070e+05</td>\n      <td>2.848070e+05</td>\n      <td>...</td>\n      <td>2.848070e+05</td>\n      <td>2.848070e+05</td>\n      <td>2.848070e+05</td>\n      <td>2.848070e+05</td>\n      <td>2.848070e+05</td>\n      <td>2.848070e+05</td>\n      <td>2.848070e+05</td>\n      <td>2.848070e+05</td>\n      <td>284807.000000</td>\n      <td>284807.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>94813.859575</td>\n      <td>3.919560e-15</td>\n      <td>5.688174e-16</td>\n      <td>-8.769071e-15</td>\n      <td>2.782312e-15</td>\n      <td>-1.552563e-15</td>\n      <td>2.010663e-15</td>\n      <td>-1.694249e-15</td>\n      <td>-1.927028e-16</td>\n      <td>-3.137024e-15</td>\n      <td>...</td>\n      <td>1.537294e-16</td>\n      <td>7.959909e-16</td>\n      <td>5.367590e-16</td>\n      <td>4.458112e-15</td>\n      <td>1.453003e-15</td>\n      <td>1.699104e-15</td>\n      <td>-3.660161e-16</td>\n      <td>-1.206049e-16</td>\n      <td>88.349619</td>\n      <td>0.001727</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>47488.145955</td>\n      <td>1.958696e+00</td>\n      <td>1.651309e+00</td>\n      <td>1.516255e+00</td>\n      <td>1.415869e+00</td>\n      <td>1.380247e+00</td>\n      <td>1.332271e+00</td>\n      <td>1.237094e+00</td>\n      <td>1.194353e+00</td>\n      <td>1.098632e+00</td>\n      <td>...</td>\n      <td>7.345240e-01</td>\n      <td>7.257016e-01</td>\n      <td>6.244603e-01</td>\n      <td>6.056471e-01</td>\n      <td>5.212781e-01</td>\n      <td>4.822270e-01</td>\n      <td>4.036325e-01</td>\n      <td>3.300833e-01</td>\n      <td>250.120109</td>\n      <td>0.041527</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>0.000000</td>\n      <td>-5.640751e+01</td>\n      <td>-7.271573e+01</td>\n      <td>-4.832559e+01</td>\n      <td>-5.683171e+00</td>\n      <td>-1.137433e+02</td>\n      <td>-2.616051e+01</td>\n      <td>-4.355724e+01</td>\n      <td>-7.321672e+01</td>\n      <td>-1.343407e+01</td>\n      <td>...</td>\n      <td>-3.483038e+01</td>\n      <td>-1.093314e+01</td>\n      <td>-4.480774e+01</td>\n      <td>-2.836627e+00</td>\n      <td>-1.029540e+01</td>\n      <td>-2.604551e+00</td>\n      <td>-2.256568e+01</td>\n      <td>-1.543008e+01</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>54201.500000</td>\n      <td>-9.203734e-01</td>\n      <td>-5.985499e-01</td>\n      <td>-8.903648e-01</td>\n      <td>-8.486401e-01</td>\n      <td>-6.915971e-01</td>\n      <td>-7.682956e-01</td>\n      <td>-5.540759e-01</td>\n      <td>-2.086297e-01</td>\n      <td>-6.430976e-01</td>\n      <td>...</td>\n      <td>-2.283949e-01</td>\n      <td>-5.423504e-01</td>\n      <td>-1.618463e-01</td>\n      <td>-3.545861e-01</td>\n      <td>-3.171451e-01</td>\n      <td>-3.269839e-01</td>\n      <td>-7.083953e-02</td>\n      <td>-5.295979e-02</td>\n      <td>5.600000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>84692.000000</td>\n      <td>1.810880e-02</td>\n      <td>6.548556e-02</td>\n      <td>1.798463e-01</td>\n      <td>-1.984653e-02</td>\n      <td>-5.433583e-02</td>\n      <td>-2.741871e-01</td>\n      <td>4.010308e-02</td>\n      <td>2.235804e-02</td>\n      <td>-5.142873e-02</td>\n      <td>...</td>\n      <td>-2.945017e-02</td>\n      <td>6.781943e-03</td>\n      <td>-1.119293e-02</td>\n      <td>4.097606e-02</td>\n      <td>1.659350e-02</td>\n      <td>-5.213911e-02</td>\n      <td>1.342146e-03</td>\n      <td>1.124383e-02</td>\n      <td>22.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>139320.500000</td>\n      <td>1.315642e+00</td>\n      <td>8.037239e-01</td>\n      <td>1.027196e+00</td>\n      <td>7.433413e-01</td>\n      <td>6.119264e-01</td>\n      <td>3.985649e-01</td>\n      <td>5.704361e-01</td>\n      <td>3.273459e-01</td>\n      <td>5.971390e-01</td>\n      <td>...</td>\n      <td>1.863772e-01</td>\n      <td>5.285536e-01</td>\n      <td>1.476421e-01</td>\n      <td>4.395266e-01</td>\n      <td>3.507156e-01</td>\n      <td>2.409522e-01</td>\n      <td>9.104512e-02</td>\n      <td>7.827995e-02</td>\n      <td>77.165000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>172792.000000</td>\n      <td>2.454930e+00</td>\n      <td>2.205773e+01</td>\n      <td>9.382558e+00</td>\n      <td>1.687534e+01</td>\n      <td>3.480167e+01</td>\n      <td>7.330163e+01</td>\n      <td>1.205895e+02</td>\n      <td>2.000721e+01</td>\n      <td>1.559499e+01</td>\n      <td>...</td>\n      <td>2.720284e+01</td>\n      <td>1.050309e+01</td>\n      <td>2.252841e+01</td>\n      <td>4.584549e+00</td>\n      <td>7.519589e+00</td>\n      <td>3.517346e+00</td>\n      <td>3.161220e+01</td>\n      <td>3.384781e+01</td>\n      <td>25691.160000</td>\n      <td>1.000000</td>\n    </tr>\n  </tbody>\n</table>\n<p>8 rows Ã— 31 columns</p>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"df[\"Class\"].plot.hist();","execution_count":59,"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 432x288 with 1 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"TRAINING_SET = df[df.Class == 1]\nTRAINING_SET.size","execution_count":60,"outputs":[{"output_type":"execute_result","execution_count":60,"data":{"text/plain":"15252"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"TRAINING_SET.head()","execution_count":61,"outputs":[{"output_type":"execute_result","execution_count":61,"data":{"text/plain":"        Time        V1        V2        V3        V4        V5        V6  \\\n541    406.0 -2.312227  1.951992 -1.609851  3.997906 -0.522188 -1.426545   \n623    472.0 -3.043541 -3.157307  1.088463  2.288644  1.359805 -1.064823   \n4920  4462.0 -2.303350  1.759247 -0.359745  2.330243 -0.821628 -0.075788   \n6108  6986.0 -4.397974  1.358367 -2.592844  2.679787 -1.128131 -1.706536   \n6329  7519.0  1.234235  3.019740 -4.304597  4.732795  3.624201 -1.357746   \n\n            V7        V8        V9  ...       V21       V22       V23  \\\n541  -2.537387  1.391657 -2.770089  ...  0.517232 -0.035049 -0.465211   \n623   0.325574 -0.067794 -0.270953  ...  0.661696  0.435477  1.375966   \n4920  0.562320 -0.399147 -0.238253  ... -0.294166 -0.932391  0.172726   \n6108 -3.496197 -0.248778 -0.247768  ...  0.573574  0.176968 -0.436207   \n6329  1.713445 -0.496358 -1.282858  ... -0.379068 -0.704181 -0.656805   \n\n           V24       V25       V26       V27       V28  Amount  Class  \n541   0.320198  0.044519  0.177840  0.261145 -0.143276    0.00      1  \n623  -0.293803  0.279798 -0.145362 -0.252773  0.035764  529.00      1  \n4920 -0.087330 -0.156114 -0.542628  0.039566 -0.153029  239.93      1  \n6108 -0.053502  0.252405 -0.657488 -0.827136  0.849573   59.00      1  \n6329 -1.632653  1.488901  0.566797 -0.010016  0.146793    1.00      1  \n\n[5 rows x 31 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Time</th>\n      <th>V1</th>\n      <th>V2</th>\n      <th>V3</th>\n      <th>V4</th>\n      <th>V5</th>\n      <th>V6</th>\n      <th>V7</th>\n      <th>V8</th>\n      <th>V9</th>\n      <th>...</th>\n      <th>V21</th>\n      <th>V22</th>\n      <th>V23</th>\n      <th>V24</th>\n      <th>V25</th>\n      <th>V26</th>\n      <th>V27</th>\n      <th>V28</th>\n      <th>Amount</th>\n      <th>Class</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>541</th>\n      <td>406.0</td>\n      <td>-2.312227</td>\n      <td>1.951992</td>\n      <td>-1.609851</td>\n      <td>3.997906</td>\n      <td>-0.522188</td>\n      <td>-1.426545</td>\n      <td>-2.537387</td>\n      <td>1.391657</td>\n      <td>-2.770089</td>\n      <td>...</td>\n      <td>0.517232</td>\n      <td>-0.035049</td>\n      <td>-0.465211</td>\n      <td>0.320198</td>\n      <td>0.044519</td>\n      <td>0.177840</td>\n      <td>0.261145</td>\n      <td>-0.143276</td>\n      <td>0.00</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>623</th>\n      <td>472.0</td>\n      <td>-3.043541</td>\n      <td>-3.157307</td>\n      <td>1.088463</td>\n      <td>2.288644</td>\n      <td>1.359805</td>\n      <td>-1.064823</td>\n      <td>0.325574</td>\n      <td>-0.067794</td>\n      <td>-0.270953</td>\n      <td>...</td>\n      <td>0.661696</td>\n      <td>0.435477</td>\n      <td>1.375966</td>\n      <td>-0.293803</td>\n      <td>0.279798</td>\n      <td>-0.145362</td>\n      <td>-0.252773</td>\n      <td>0.035764</td>\n      <td>529.00</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4920</th>\n      <td>4462.0</td>\n      <td>-2.303350</td>\n      <td>1.759247</td>\n      <td>-0.359745</td>\n      <td>2.330243</td>\n      <td>-0.821628</td>\n      <td>-0.075788</td>\n      <td>0.562320</td>\n      <td>-0.399147</td>\n      <td>-0.238253</td>\n      <td>...</td>\n      <td>-0.294166</td>\n      <td>-0.932391</td>\n      <td>0.172726</td>\n      <td>-0.087330</td>\n      <td>-0.156114</td>\n      <td>-0.542628</td>\n      <td>0.039566</td>\n      <td>-0.153029</td>\n      <td>239.93</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>6108</th>\n      <td>6986.0</td>\n      <td>-4.397974</td>\n      <td>1.358367</td>\n      <td>-2.592844</td>\n      <td>2.679787</td>\n      <td>-1.128131</td>\n      <td>-1.706536</td>\n      <td>-3.496197</td>\n      <td>-0.248778</td>\n      <td>-0.247768</td>\n      <td>...</td>\n      <td>0.573574</td>\n      <td>0.176968</td>\n      <td>-0.436207</td>\n      <td>-0.053502</td>\n      <td>0.252405</td>\n      <td>-0.657488</td>\n      <td>-0.827136</td>\n      <td>0.849573</td>\n      <td>59.00</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>6329</th>\n      <td>7519.0</td>\n      <td>1.234235</td>\n      <td>3.019740</td>\n      <td>-4.304597</td>\n      <td>4.732795</td>\n      <td>3.624201</td>\n      <td>-1.357746</td>\n      <td>1.713445</td>\n      <td>-0.496358</td>\n      <td>-1.282858</td>\n      <td>...</td>\n      <td>-0.379068</td>\n      <td>-0.704181</td>\n      <td>-0.656805</td>\n      <td>-1.632653</td>\n      <td>1.488901</td>\n      <td>0.566797</td>\n      <td>-0.010016</td>\n      <td>0.146793</td>\n      <td>1.00</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 31 columns</p>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"TRAINING_SET = TRAINING_SET.drop(columns=['Time', 'Amount', 'Class'])\nTRAINING_SET.head()","execution_count":62,"outputs":[{"output_type":"execute_result","execution_count":62,"data":{"text/plain":"            V1        V2        V3        V4        V5        V6        V7  \\\n541  -2.312227  1.951992 -1.609851  3.997906 -0.522188 -1.426545 -2.537387   \n623  -3.043541 -3.157307  1.088463  2.288644  1.359805 -1.064823  0.325574   \n4920 -2.303350  1.759247 -0.359745  2.330243 -0.821628 -0.075788  0.562320   \n6108 -4.397974  1.358367 -2.592844  2.679787 -1.128131 -1.706536 -3.496197   \n6329  1.234235  3.019740 -4.304597  4.732795  3.624201 -1.357746  1.713445   \n\n            V8        V9       V10  ...       V19       V20       V21  \\\n541   1.391657 -2.770089 -2.772272  ...  0.416956  0.126911  0.517232   \n623  -0.067794 -0.270953 -0.838587  ...  0.283345  2.102339  0.661696   \n4920 -0.399147 -0.238253 -1.525412  ... -1.334441 -0.430022 -0.294166   \n6108 -0.248778 -0.247768 -4.801637  ...  0.308334 -0.171608  0.573574   \n6329 -0.496358 -1.282858 -2.447469  ... -2.721853  0.009061 -0.379068   \n\n           V22       V23       V24       V25       V26       V27       V28  \n541  -0.035049 -0.465211  0.320198  0.044519  0.177840  0.261145 -0.143276  \n623   0.435477  1.375966 -0.293803  0.279798 -0.145362 -0.252773  0.035764  \n4920 -0.932391  0.172726 -0.087330 -0.156114 -0.542628  0.039566 -0.153029  \n6108  0.176968 -0.436207 -0.053502  0.252405 -0.657488 -0.827136  0.849573  \n6329 -0.704181 -0.656805 -1.632653  1.488901  0.566797 -0.010016  0.146793  \n\n[5 rows x 28 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>V1</th>\n      <th>V2</th>\n      <th>V3</th>\n      <th>V4</th>\n      <th>V5</th>\n      <th>V6</th>\n      <th>V7</th>\n      <th>V8</th>\n      <th>V9</th>\n      <th>V10</th>\n      <th>...</th>\n      <th>V19</th>\n      <th>V20</th>\n      <th>V21</th>\n      <th>V22</th>\n      <th>V23</th>\n      <th>V24</th>\n      <th>V25</th>\n      <th>V26</th>\n      <th>V27</th>\n      <th>V28</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>541</th>\n      <td>-2.312227</td>\n      <td>1.951992</td>\n      <td>-1.609851</td>\n      <td>3.997906</td>\n      <td>-0.522188</td>\n      <td>-1.426545</td>\n      <td>-2.537387</td>\n      <td>1.391657</td>\n      <td>-2.770089</td>\n      <td>-2.772272</td>\n      <td>...</td>\n      <td>0.416956</td>\n      <td>0.126911</td>\n      <td>0.517232</td>\n      <td>-0.035049</td>\n      <td>-0.465211</td>\n      <td>0.320198</td>\n      <td>0.044519</td>\n      <td>0.177840</td>\n      <td>0.261145</td>\n      <td>-0.143276</td>\n    </tr>\n    <tr>\n      <th>623</th>\n      <td>-3.043541</td>\n      <td>-3.157307</td>\n      <td>1.088463</td>\n      <td>2.288644</td>\n      <td>1.359805</td>\n      <td>-1.064823</td>\n      <td>0.325574</td>\n      <td>-0.067794</td>\n      <td>-0.270953</td>\n      <td>-0.838587</td>\n      <td>...</td>\n      <td>0.283345</td>\n      <td>2.102339</td>\n      <td>0.661696</td>\n      <td>0.435477</td>\n      <td>1.375966</td>\n      <td>-0.293803</td>\n      <td>0.279798</td>\n      <td>-0.145362</td>\n      <td>-0.252773</td>\n      <td>0.035764</td>\n    </tr>\n    <tr>\n      <th>4920</th>\n      <td>-2.303350</td>\n      <td>1.759247</td>\n      <td>-0.359745</td>\n      <td>2.330243</td>\n      <td>-0.821628</td>\n      <td>-0.075788</td>\n      <td>0.562320</td>\n      <td>-0.399147</td>\n      <td>-0.238253</td>\n      <td>-1.525412</td>\n      <td>...</td>\n      <td>-1.334441</td>\n      <td>-0.430022</td>\n      <td>-0.294166</td>\n      <td>-0.932391</td>\n      <td>0.172726</td>\n      <td>-0.087330</td>\n      <td>-0.156114</td>\n      <td>-0.542628</td>\n      <td>0.039566</td>\n      <td>-0.153029</td>\n    </tr>\n    <tr>\n      <th>6108</th>\n      <td>-4.397974</td>\n      <td>1.358367</td>\n      <td>-2.592844</td>\n      <td>2.679787</td>\n      <td>-1.128131</td>\n      <td>-1.706536</td>\n      <td>-3.496197</td>\n      <td>-0.248778</td>\n      <td>-0.247768</td>\n      <td>-4.801637</td>\n      <td>...</td>\n      <td>0.308334</td>\n      <td>-0.171608</td>\n      <td>0.573574</td>\n      <td>0.176968</td>\n      <td>-0.436207</td>\n      <td>-0.053502</td>\n      <td>0.252405</td>\n      <td>-0.657488</td>\n      <td>-0.827136</td>\n      <td>0.849573</td>\n    </tr>\n    <tr>\n      <th>6329</th>\n      <td>1.234235</td>\n      <td>3.019740</td>\n      <td>-4.304597</td>\n      <td>4.732795</td>\n      <td>3.624201</td>\n      <td>-1.357746</td>\n      <td>1.713445</td>\n      <td>-0.496358</td>\n      <td>-1.282858</td>\n      <td>-2.447469</td>\n      <td>...</td>\n      <td>-2.721853</td>\n      <td>0.009061</td>\n      <td>-0.379068</td>\n      <td>-0.704181</td>\n      <td>-0.656805</td>\n      <td>-1.632653</td>\n      <td>1.488901</td>\n      <td>0.566797</td>\n      <td>-0.010016</td>\n      <td>0.146793</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 28 columns</p>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"class CreditCardDataset(torch.utils.data.Dataset):\n    def __init__(self, dataframe):\n        self.dataframe = dataframe\n    def __len__(self):\n        return len(self.dataframe)\n    def __getitem__(self, idx):\n        if torch.is_tensor(idx):\n            idx = idx.tolist()\n        return np.array(self.dataframe.iloc[idx], dtype=np.float32)","execution_count":63,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"creditCardDataset = CreditCardDataset(TRAINING_SET)\ncreditCardDataLoader = torch.utils.data.DataLoader(\n    creditCardDataset,\n    batch_size=BATCH_SIZE,\n    shuffle=True,\n    num_workers=4,\n    drop_last=True\n)","execution_count":64,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class Generator(torch.nn.Module):\n    def __init__(self):\n        super(Generator, self).__init__()\n        self.fcn = torch.nn.Sequential(\n            torch.nn.Linear(\n                in_features=NOISE_DIM,\n                out_features=128,\n                bias=True\n            ),\n            torch.nn.ReLU(),\n            torch.nn.Linear(\n                in_features=128,\n                out_features=256,\n                bias=True\n            ),\n            torch.nn.ReLU(),\n            torch.nn.Linear(\n                in_features=256,\n                out_features=FEATURES_DIM,\n                bias=True\n            ),\n            torch.nn.Tanh(),\n        )\n    def forward(self, batch):\n        return self.fcn(batch)","execution_count":65,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class Discriminator(torch.nn.Module):\n    def __init__(self):\n        super(Discriminator, self).__init__()\n        self.fcn = torch.nn.Sequential(\n            torch.nn.Linear(\n                in_features=FEATURES_DIM,\n                out_features=256,\n                bias=True\n            ),\n            torch.nn.LeakyReLU(),\n            torch.nn.Linear(\n                in_features=256,\n                out_features=256,\n                bias=True\n            ),\n            torch.nn.LeakyReLU(),\n            torch.nn.Linear(\n                in_features=256,\n                out_features=1,\n                bias=True\n            ),\n            torch.nn.Sigmoid(),\n        )\n    def forward(self, batch):\n        return self.fcn(batch)","execution_count":66,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"generator = Generator()\ndiscriminator = Discriminator()\n\ngeneratorOptimizer = torch.optim.Adam(\n    generator.parameters(),\n    lr=GENERATOR_LEARNING_RATE\n)\n\ndiscriminatorOptimizer = torch.optim.Adam(\n    discriminator.parameters(),\n    lr=DISCRIMINATOR_LEARNING_RATE\n)\n\ncriterion = torch.nn.BCELoss()","execution_count":67,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"realLabels = torch.ones(BATCH_SIZE, 1)\nfakeLabels = torch.zeros(BATCH_SIZE, 1)","execution_count":68,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"itrDataLoader = iter(creditCardDataLoader)\nfor e in range(TRAIN_EPOCHS):\n    for s in range(TRAIN_STEPS):\n        # Train Discriminator K Steps\n        for k in range(K_DISCRIMINATOR_STEPS):\n            try:\n                xReal = next(itrDataLoader)\n            except:\n                itrDataLoader = iter(creditCardDataLoader)\n                xReal = next(itrDataLoader)\n            zNoise = torch.randn(BATCH_SIZE, NOISE_DIM)\n            xFake = generator(zNoise)\n            discriminatorOptimizer.zero_grad()\n            yReal = discriminator(xReal)\n            yFake = discriminator(xFake)\n            dX = criterion(yReal, realLabels)\n            dGz = criterion(yFake, fakeLabels)\n            dX.backward()\n            dGz.backward()\n            discriminatorOptimizer.step()\n        # Train Generator\n        zNoise = torch.randn(BATCH_SIZE, NOISE_DIM)\n        generatorOptimizer.zero_grad()\n        gZ = generator(zNoise)\n        dGz = discriminator(gZ)\n        gLoss = criterion(dGz, realLabels)\n        gLoss.backward()\n        generatorOptimizer.step()\n    if e % 10 == 0:\n        print(\"E:{}\".format(e))","execution_count":69,"outputs":[{"output_type":"stream","text":"E:0\nE:10\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"zNoise = torch.randn(5, NOISE_DIM)\ngZ = generator(zNoise)\npd.DataFrame(gZ.detach().numpy())","execution_count":77,"outputs":[{"output_type":"error","ename":"RuntimeError","evalue":"Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead.","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-77-b4765660dde6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mzNoise\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNOISE_DIM\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mgZ\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzNoise\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgZ\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m: Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead."]}]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}